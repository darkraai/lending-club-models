{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>installment</th>\n",
       "      <th>dti</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>10.65</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>162.87</td>\n",
       "      <td>27.65</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>15.27</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>59.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>15.96</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>84.33</td>\n",
       "      <td>8.72</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>13.49</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>339.31</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>156.46</td>\n",
       "      <td>11.20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.0</td>\n",
       "      <td>18.64</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>109.43</td>\n",
       "      <td>5.35</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60.0</td>\n",
       "      <td>21.28</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>152.39</td>\n",
       "      <td>5.55</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60.0</td>\n",
       "      <td>12.69</td>\n",
       "      <td>5375.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>121.45</td>\n",
       "      <td>18.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60.0</td>\n",
       "      <td>14.65</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>153.45</td>\n",
       "      <td>16.12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.0</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>402.54</td>\n",
       "      <td>10.78</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   term  int_rate  loan_amnt  verification_status  annual_inc  installment  \\\n",
       "0  36.0     10.65     5000.0                  0.0     24000.0       162.87   \n",
       "1  60.0     15.27     2500.0                  1.0     30000.0        59.83   \n",
       "2  36.0     15.96     2400.0                  0.0     12252.0        84.33   \n",
       "3  36.0     13.49    10000.0                  1.0     49200.0       339.31   \n",
       "4  36.0      7.90     5000.0                  1.0     36000.0       156.46   \n",
       "5  36.0     18.64     3000.0                  1.0     48000.0       109.43   \n",
       "6  60.0     21.28     5600.0                  1.0     40000.0       152.39   \n",
       "7  60.0     12.69     5375.0                  0.0     15000.0       121.45   \n",
       "8  60.0     14.65     6500.0                  0.0     72000.0       153.45   \n",
       "9  36.0     12.69    12000.0                  1.0     75000.0       402.54   \n",
       "\n",
       "     dti  loan_status  \n",
       "0  27.65          1.0  \n",
       "1   1.00          0.0  \n",
       "2   8.72          1.0  \n",
       "3  20.00          1.0  \n",
       "4  11.20          1.0  \n",
       "5   5.35          1.0  \n",
       "6   5.55          0.0  \n",
       "7  18.08          0.0  \n",
       "8  16.12          1.0  \n",
       "9  10.78          1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed_data.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>installment</th>\n",
       "      <th>dti</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225180</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106603</td>\n",
       "      <td>0.104466</td>\n",
       "      <td>0.691423</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.420363</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.137061</td>\n",
       "      <td>0.031330</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449514</td>\n",
       "      <td>0.055072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046966</td>\n",
       "      <td>0.048720</td>\n",
       "      <td>0.218055</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345163</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.234527</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.500125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108999</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.167519</td>\n",
       "      <td>0.099916</td>\n",
       "      <td>0.280070</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.562738</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228436</td>\n",
       "      <td>0.066535</td>\n",
       "      <td>0.133783</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.674271</td>\n",
       "      <td>0.147826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.187825</td>\n",
       "      <td>0.097027</td>\n",
       "      <td>0.138785</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.311365</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060916</td>\n",
       "      <td>0.075067</td>\n",
       "      <td>0.452113</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.394170</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350268</td>\n",
       "      <td>0.097780</td>\n",
       "      <td>0.403101</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.311365</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365497</td>\n",
       "      <td>0.274580</td>\n",
       "      <td>0.269567</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   term  int_rate  loan_amnt  verification_status  annual_inc  installment  \\\n",
       "0   0.0  0.225180   0.130435                  0.0    0.106603     0.104466   \n",
       "1   1.0  0.420363   0.057971                  1.0    0.137061     0.031330   \n",
       "2   0.0  0.449514   0.055072                  0.0    0.046966     0.048720   \n",
       "3   0.0  0.345163   0.275362                  1.0    0.234527     0.229700   \n",
       "4   0.0  0.108999   0.130435                  1.0    0.167519     0.099916   \n",
       "5   0.0  0.562738   0.072464                  1.0    0.228436     0.066535   \n",
       "6   1.0  0.674271   0.147826                  1.0    0.187825     0.097027   \n",
       "7   1.0  0.311365   0.141304                  0.0    0.060916     0.075067   \n",
       "8   1.0  0.394170   0.173913                  0.0    0.350268     0.097780   \n",
       "9   0.0  0.311365   0.333333                  1.0    0.365497     0.274580   \n",
       "\n",
       "        dti  loan_status  \n",
       "0  0.691423          1.0  \n",
       "1  0.025006          0.0  \n",
       "2  0.218055          1.0  \n",
       "3  0.500125          1.0  \n",
       "4  0.280070          1.0  \n",
       "5  0.133783          1.0  \n",
       "6  0.138785          0.0  \n",
       "7  0.452113          0.0  \n",
       "8  0.403101          1.0  \n",
       "9  0.269567          1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"normalized_data.csv\")\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"loan_amnt\", \"annual_inc\", \"dti\", \"term\", \"verification_status\"]]\n",
    "y = df[[\"loan_status\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[ 1792  9750]\n",
      " [ 3671 37944]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.16      0.21     11542\n",
      "         1.0       0.80      0.91      0.85     41615\n",
      "\n",
      "    accuracy                           0.75     53157\n",
      "   macro avg       0.56      0.53      0.53     53157\n",
      "weighted avg       0.69      0.75      0.71     53157\n",
      "\n",
      "Accurary Score 0.7475214929360197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accurary Score\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  [0.79775883 0.80036313 0.80081049 0.79715347 0.79873486 0.7978943\n",
      " 0.79649601 0.79859707 0.79877296 0.80092325]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "scores = cross_val_score(clf, X, y, scoring = \"precision\", cv=cv)\n",
    "print(\"Precision: \", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dti           0.339790\n",
      "int_rate      0.233281\n",
      "annual_inc    0.219340\n",
      "loan_amnt     0.207589\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features_imp = pd.Series(clf.feature_importances_,index=[\"int_rate\", \"loan_amnt\", \"annual_inc\", \"dti\"]).sort_values(ascending=False)\n",
    "print(features_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=100,\n",
    "                         learning_rate=1)\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[  881 10766]\n",
      " [  711 40799]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.08      0.13     11647\n",
      "         1.0       0.79      0.98      0.88     41510\n",
      "\n",
      "    accuracy                           0.78     53157\n",
      "   macro avg       0.67      0.53      0.50     53157\n",
      "weighted avg       0.74      0.78      0.71     53157\n",
      "\n",
      "Accurary Score 0.7840924055157364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test,y_pred))\n",
    "print(\"Classification Report:\", classification_report(y_test,y_pred))\n",
    "print(\"Accurary Score\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[  909 10738]\n",
      " [  726 40784]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.08      0.14     11647\n",
      "         1.0       0.79      0.98      0.88     41510\n",
      "\n",
      "    accuracy                           0.78     53157\n",
      "   macro avg       0.67      0.53      0.51     53157\n",
      "weighted avg       0.74      0.78      0.71     53157\n",
      "\n",
      "Accurary Score 0.7843369640875143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test,y_pred))\n",
    "print(\"Classification Report:\", classification_report(y_test,y_pred))\n",
    "print(\"Accurary Score\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7915841776328558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32 0.68]\n",
      " [0.16 0.84]\n",
      " [0.52 0.48]\n",
      " ...\n",
      " [0.1  0.9 ]\n",
      " [0.02 0.98]\n",
      " [0.06 0.94]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "Confusion Matrix: [[ 9697  1894]\n",
      " [27399 14167]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.26      0.84      0.40     11591\n",
      "         1.0       0.88      0.34      0.49     41566\n",
      "\n",
      "    accuracy                           0.45     53157\n",
      "   macro avg       0.57      0.59      0.45     53157\n",
      "weighted avg       0.75      0.45      0.47     53157\n",
      "\n",
      "Accurary Score 0.44893428899298304\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.9\n",
    "\n",
    "predicted = clf.predict_proba(X_test)\n",
    "print(predicted)\n",
    "predicted[:,0] = (predicted[:,0] < threshold).astype('int')\n",
    "predicted[:,1] = (predicted[:,1] >= threshold).astype('int')\n",
    "print(predicted)\n",
    "\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, predicted[:,1]))\n",
    "print(\"Classification Report:\", classification_report(y_test, predicted[:,1]))\n",
    "print(\"Accurary Score\", accuracy_score(y_test, predicted[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:  1.0min remaining:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.1min finished\n",
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 50, 90, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [25, 50, 100]},\n",
       "                   random_state=42, scoring='precision', verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "random_grid = {'bootstrap': [True, False],\n",
    "               'max_depth': [10, 50, 90, None],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'n_estimators': [25, 50, 100]}\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(scoring = \"precision\", estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[ 1833  9758]\n",
      " [ 2822 38744]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.39      0.16      0.23     11591\n",
      "         1.0       0.80      0.93      0.86     41566\n",
      "\n",
      "    accuracy                           0.76     53157\n",
      "   macro avg       0.60      0.55      0.54     53157\n",
      "weighted avg       0.71      0.76      0.72     53157\n",
      "\n",
      "Accurary Score 0.7633425513102696\n",
      "[[0.29416667 0.70583333]\n",
      " [0.36166667 0.63833333]\n",
      " [0.36666667 0.63333333]\n",
      " ...\n",
      " [0.05916667 0.94083333]\n",
      " [0.         1.        ]\n",
      " [0.16       0.84      ]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 0.]]\n",
      "Confusion Matrix: [[ 9807  1784]\n",
      " [28000 13566]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.26      0.85      0.40     11591\n",
      "         1.0       0.88      0.33      0.48     41566\n",
      "\n",
      "    accuracy                           0.44     53157\n",
      "   macro avg       0.57      0.59      0.44     53157\n",
      "weighted avg       0.75      0.44      0.46     53157\n",
      "\n",
      "Accurary Score 0.4396974998589085\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_random.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test,y_pred))\n",
    "print(\"Classification Report:\", classification_report(y_test,y_pred))\n",
    "print(\"Accurary Score\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "threshold = 0.90\n",
    "\n",
    "predicted = rf_random.predict_proba(X_test)\n",
    "predicted[:,0] = (predicted[:,0] < threshold).astype('int')\n",
    "predicted[:,1] = (predicted[:,1] >= threshold).astype('int')\n",
    "\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, predicted[:,1]))\n",
    "print(\"Classification Report:\", classification_report(y_test, predicted[:,1]))\n",
    "print(\"Accurary Score\", accuracy_score(y_test, predicted[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 35, 60, 85, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [0, 66, 133, 200]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 0, stop = 200, num = 4)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  6.4min finished\n",
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[  713 10878]\n",
      " [  581 40985]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.06      0.11     11591\n",
      "         1.0       0.79      0.99      0.88     41566\n",
      "\n",
      "    accuracy                           0.78     53157\n",
      "   macro avg       0.67      0.52      0.49     53157\n",
      "weighted avg       0.74      0.78      0.71     53157\n",
      "\n",
      "Accurary Score 0.7844310250766597\n",
      "[[0.27401703 0.72598297]\n",
      " [0.11649042 0.88350958]\n",
      " [0.46169772 0.53830228]\n",
      " ...\n",
      " [0.14828097 0.85171903]\n",
      " [0.1692583  0.8307417 ]\n",
      " [0.18576861 0.81423139]]\n",
      "Confusion Matrix: [[11034   557]\n",
      " [34165  7401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.24      0.95      0.39     11591\n",
      "         1.0       0.93      0.18      0.30     41566\n",
      "\n",
      "    accuracy                           0.35     53157\n",
      "   macro avg       0.59      0.56      0.34     53157\n",
      "weighted avg       0.78      0.35      0.32     53157\n",
      "\n",
      "Accurary Score 0.34680286697894913\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 30, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_random.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accurary Score\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "threshold = 0.90\n",
    "\n",
    "predicted = rf_random.predict_proba(X_test)\n",
    "print(predicted)\n",
    "predicted[:,0] = (predicted[:,0] < threshold).astype('int')\n",
    "predicted[:,1] = (predicted[:,1] >= threshold).astype('int')\n",
    "\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, predicted[:,1]))\n",
    "print(classification_report(y_test, predicted[:,1]))\n",
    "print(\"Accurary Score\", accuracy_score(y_test, predicted[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd21ad34dd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import forestci as fci\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "idx_paid = np.where(y_test == 1)[0]\n",
    "idx_default = np.where(y_test == 0)[0]\n",
    "\n",
    "# Histogram predictions without error bars:\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.hist(y_pred[idx_paid], histtype='step', label='Loan Paid')\n",
    "ax.hist(y_pred[idx_default], histtype='step', label='Loan Defaulted')\n",
    "ax.set_xlabel('Prediction (loan default probability)')\n",
    "ax.set_ylabel('Number of observations')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-06a5e4d37193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate the variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m V_unbiased = fci.random_forest_error(clf, X_train,\n\u001b[0;32m----> 3\u001b[0;31m                                             X_test)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Plot forest prediction for emails and standard deviation for estimates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/forestci/forestci.py\u001b[0m in \u001b[0;36mrandom_forest_error\u001b[0;34m(forest, X_train, X_test, inbag, calibrate, memory_constrained, memory_limit)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0mn_trees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     V_IJ = _core_computation(\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_centered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_constrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m     \u001b[0mV_IJ_unbiased\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_bias_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_IJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_centered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/forestci/forestci.py\u001b[0m in \u001b[0;36m_core_computation\u001b[0;34m(X_train, X_test, inbag, pred_centered, n_trees, memory_constrained, memory_limit, test_mode)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \"\"\"\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmemory_constrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbag\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_centered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmemory_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2242\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calculate the variance\n",
    "V_unbiased = fci.random_forest_error(clf, X_train,\n",
    "                                            X_test)\n",
    "\n",
    "# Plot forest prediction for emails and standard deviation for estimates\n",
    "# Blue points are spam emails; Green points are non-spam emails\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.scatter(y_pred[idx_paid, 1],\n",
    "           np.sqrt(V_unbiased[idx_paid]),\n",
    "           label='Loan Paid')\n",
    "\n",
    "ax.scatter(y_pred[idx_default, 1],\n",
    "           np.sqrt(V_unbiased[idx_default]),\n",
    "           label='Loan Defaulted')\n",
    "\n",
    "ax.set_xlabel('Prediction (loan default probability)')\n",
    "ax.set_ylabel('Standard deviation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96 1.   0.94 ... 0.98 0.94 0.98]\n",
      "0.038987071421494\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "idx_paid = np.where(y_pred >= 0.9)[0]\n",
    "idx_default = np.where(y_test >= 0.9)[0]\n",
    "\n",
    "print(y_pred[idx_paid,1])\n",
    "\n",
    "print(np.std(y_pred[idx_paid,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (19,55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data shape:  (887379, 74)\n",
      "Raw selected features shape:  (887379, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape before drop:  (887375, 9)\n",
      "Data shape after drop:  (265781, 9)\n",
      "Fully Paid            207723\n",
      "Charged Off            45248\n",
      "Late (31-120 days)     11591\n",
      "Default                 1219\n",
      "Name: loan_status, dtype: int64\n",
      "0.0%\n",
      "0.38%\n",
      "0.75%\n",
      "1.13%\n",
      "1.5%\n",
      "1.88%\n",
      "2.26%\n",
      "2.63%\n",
      "3.01%\n",
      "3.39%\n",
      "3.76%\n",
      "4.14%\n",
      "4.51%\n",
      "4.89%\n",
      "5.27%\n",
      "5.64%\n",
      "6.02%\n",
      "6.4%\n",
      "6.77%\n",
      "7.15%\n",
      "7.52%\n",
      "7.9%\n",
      "8.28%\n",
      "8.65%\n",
      "9.03%\n",
      "9.41%\n",
      "9.78%\n",
      "10.16%\n",
      "10.53%\n",
      "10.91%\n",
      "11.29%\n",
      "11.66%\n",
      "12.04%\n",
      "12.42%\n",
      "12.79%\n",
      "13.17%\n",
      "13.54%\n",
      "13.92%\n",
      "14.3%\n",
      "14.67%\n",
      "15.05%\n",
      "15.43%\n",
      "15.8%\n",
      "16.18%\n",
      "16.55%\n",
      "16.93%\n",
      "17.31%\n",
      "17.68%\n",
      "18.06%\n",
      "18.44%\n",
      "18.81%\n",
      "19.19%\n",
      "19.56%\n",
      "19.94%\n",
      "20.32%\n",
      "20.69%\n",
      "21.07%\n",
      "21.45%\n",
      "21.82%\n",
      "22.2%\n",
      "22.57%\n",
      "22.95%\n",
      "23.33%\n",
      "23.7%\n",
      "24.08%\n",
      "24.46%\n",
      "24.83%\n",
      "25.21%\n",
      "25.58%\n",
      "25.96%\n",
      "26.34%\n",
      "26.71%\n",
      "27.09%\n",
      "27.47%\n",
      "27.84%\n",
      "28.22%\n",
      "28.59%\n",
      "28.97%\n",
      "29.35%\n",
      "29.72%\n",
      "30.1%\n",
      "30.48%\n",
      "30.85%\n",
      "31.23%\n",
      "31.6%\n",
      "31.98%\n",
      "32.36%\n",
      "32.73%\n",
      "33.11%\n",
      "33.49%\n",
      "33.86%\n",
      "34.24%\n",
      "34.61%\n",
      "34.99%\n",
      "35.37%\n",
      "35.74%\n",
      "36.12%\n",
      "36.5%\n",
      "36.87%\n",
      "37.25%\n",
      "37.62%\n",
      "38.0%\n",
      "38.38%\n",
      "38.75%\n",
      "39.13%\n",
      "39.51%\n",
      "39.88%\n",
      "40.26%\n",
      "40.63%\n",
      "41.01%\n",
      "41.39%\n",
      "41.76%\n",
      "42.14%\n",
      "42.52%\n",
      "42.89%\n",
      "43.27%\n",
      "43.64%\n",
      "44.02%\n",
      "44.4%\n",
      "44.77%\n",
      "45.15%\n",
      "45.53%\n",
      "45.9%\n",
      "46.28%\n",
      "46.65%\n",
      "47.03%\n",
      "47.41%\n",
      "47.78%\n",
      "48.16%\n",
      "48.54%\n",
      "48.91%\n",
      "49.29%\n",
      "49.66%\n",
      "50.04%\n",
      "50.42%\n",
      "50.79%\n",
      "51.17%\n",
      "51.55%\n",
      "51.92%\n",
      "52.3%\n",
      "52.67%\n",
      "53.05%\n",
      "53.43%\n",
      "53.8%\n",
      "54.18%\n",
      "54.56%\n",
      "54.93%\n",
      "55.31%\n",
      "55.68%\n",
      "56.06%\n",
      "56.44%\n",
      "56.81%\n",
      "57.19%\n",
      "57.57%\n",
      "57.94%\n",
      "58.32%\n",
      "58.69%\n",
      "59.07%\n",
      "59.45%\n",
      "59.82%\n",
      "60.2%\n",
      "60.58%\n",
      "60.95%\n",
      "61.33%\n",
      "61.7%\n",
      "62.08%\n",
      "62.46%\n",
      "62.83%\n",
      "63.21%\n",
      "63.59%\n",
      "63.96%\n",
      "64.34%\n",
      "64.71%\n",
      "65.09%\n",
      "65.47%\n",
      "65.84%\n",
      "66.22%\n",
      "66.6%\n",
      "66.97%\n",
      "67.35%\n",
      "67.72%\n",
      "68.1%\n",
      "68.48%\n",
      "68.85%\n",
      "69.23%\n",
      "69.61%\n",
      "69.98%\n",
      "70.36%\n",
      "70.73%\n",
      "71.11%\n",
      "71.49%\n",
      "71.86%\n",
      "72.24%\n",
      "72.62%\n",
      "72.99%\n",
      "73.37%\n",
      "73.74%\n",
      "74.12%\n",
      "74.5%\n",
      "74.87%\n",
      "75.25%\n",
      "75.63%\n",
      "76.0%\n",
      "76.38%\n",
      "76.75%\n",
      "77.13%\n",
      "77.51%\n",
      "77.88%\n",
      "78.26%\n",
      "78.64%\n",
      "79.01%\n",
      "79.39%\n",
      "79.76%\n",
      "80.14%\n",
      "80.52%\n",
      "80.89%\n",
      "81.27%\n",
      "81.65%\n",
      "82.02%\n",
      "82.4%\n",
      "82.77%\n",
      "83.15%\n",
      "83.53%\n",
      "83.9%\n",
      "84.28%\n",
      "84.66%\n",
      "85.03%\n",
      "85.41%\n",
      "85.78%\n",
      "86.16%\n",
      "86.54%\n",
      "86.91%\n",
      "87.29%\n",
      "87.67%\n",
      "88.04%\n",
      "88.42%\n",
      "88.79%\n",
      "89.17%\n",
      "89.55%\n",
      "89.92%\n",
      "90.3%\n",
      "90.68%\n",
      "91.05%\n",
      "91.43%\n",
      "91.8%\n",
      "92.18%\n",
      "92.56%\n",
      "92.93%\n",
      "93.31%\n",
      "93.69%\n",
      "94.06%\n",
      "94.44%\n",
      "94.81%\n",
      "95.19%\n",
      "95.57%\n",
      "95.94%\n",
      "96.32%\n",
      "96.7%\n",
      "97.07%\n",
      "97.45%\n",
      "97.82%\n",
      "98.2%\n",
      "98.58%\n",
      "98.95%\n",
      "99.33%\n",
      "99.71%\n",
      "(265781, 9)\n",
      "<bound method NDFrame.head of        term int_rate loan_amnt annual_inc installment    dti  \\\n",
      "0        36    10.65      5000      24000      162.87  27.65   \n",
      "1        60    15.27      2500      30000       59.83      1   \n",
      "2        36    15.96      2400      12252       84.33   8.72   \n",
      "3        36    13.49     10000      49200      339.31     20   \n",
      "4        36      7.9      5000      36000      156.46   11.2   \n",
      "...     ...      ...       ...        ...         ...    ...   \n",
      "265776   36    15.99      4200      48000      147.64  36.93   \n",
      "265777   36     6.03     10775      54000      327.95  13.22   \n",
      "265778   36    16.49      6225      27000      220.37  18.58   \n",
      "265779   36     8.67      4000      50000      126.59  12.63   \n",
      "265780   36    19.24     10850      32000      399.04  29.44   \n",
      "\n",
      "       verification_status loan_status total_pymnt  \n",
      "0                        0           1     5861.07  \n",
      "1                        1           0     1008.71  \n",
      "2                        0           1     3003.65  \n",
      "3                        1           1     12226.3  \n",
      "4                        1           1     5631.38  \n",
      "...                    ...         ...         ...  \n",
      "265776                   0           0     1026.02  \n",
      "265777                   0           1     11071.9  \n",
      "265778                   1           1     7050.46  \n",
      "265779                   0           1     4158.02  \n",
      "265780                   0           0     2396.05  \n",
      "\n",
      "[265781 rows x 9 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data and get selected columns\n",
    "raw_data = pd.read_csv(\"lc_loan.csv\", error_bad_lines=False)\n",
    "print(\"Raw data shape: \", raw_data.shape)\n",
    "raw_selected_features = raw_data[\n",
    "    ['term', 'int_rate', 'loan_amnt', 'annual_inc', 'installment', 'dti', 'verification_status', 'loan_status', 'total_pymnt']]\n",
    "print(\"Raw selected features shape: \", raw_selected_features.shape)\n",
    "\n",
    "# drop certain rows\n",
    "raw_selected_features.dropna(inplace=True)\n",
    "print(\"Data shape before drop: \", raw_selected_features.shape)\n",
    "\n",
    "raw_selected_features = raw_selected_features.loc[((raw_selected_features['loan_status'] == \"Fully Paid\")\n",
    "                                                   | (raw_selected_features['loan_status'] == \"Charged Off\")\n",
    "                                                   | (raw_selected_features['loan_status'] == \"Default\")\n",
    "                                                   | (raw_selected_features['loan_status'] == \"Late (31-120 days)\"))]\n",
    "print(\"Data shape after drop: \", raw_selected_features.shape)\n",
    "print(raw_selected_features['loan_status'].value_counts())\n",
    "\n",
    "# pre process data\n",
    "df_processed = pd.DataFrame(index=range(raw_selected_features.shape[0]),\n",
    "                            columns=['term', 'int_rate', 'loan_amnt', 'annual_inc', 'installment', 'dti', 'verification_status', 'loan_status', 'total_pymnt'])\n",
    "\n",
    "\n",
    "def preProcessData():\n",
    "    for i in range(raw_selected_features.shape[0]):\n",
    "        if i % 1000 == 0:\n",
    "            print(str(round((i/raw_selected_features.shape[0])*100, 2)) + \"%\")\n",
    "\n",
    "        # good to go features\n",
    "        df_processed.iat[i, df_processed.columns.get_loc('int_rate')] = raw_selected_features['int_rate'].iloc[i]\n",
    "        df_processed.iat[i, df_processed.columns.get_loc('loan_amnt')] = raw_selected_features['loan_amnt'].iloc[i]\n",
    "        df_processed.iat[i, df_processed.columns.get_loc('annual_inc')] = raw_selected_features.iloc[i]['annual_inc']\n",
    "        df_processed.iat[i, df_processed.columns.get_loc('installment')] = raw_selected_features.iloc[i]['installment']\n",
    "        df_processed.iat[i, df_processed.columns.get_loc('dti')] = raw_selected_features.iloc[i]['dti']\n",
    "        df_processed.iat[i, df_processed.columns.get_loc('total_pymnt')] = raw_selected_features.iloc[i]['total_pymnt']\n",
    "\n",
    "        # features to convert\n",
    "        df_processed.iat[i, df_processed.columns.get_loc('term')] = float(\n",
    "            raw_selected_features.iloc[i]['term'].split()[0])\n",
    "        df_processed.iat[i, df_processed.columns.get_loc('loan_status')] = raw_selected_features.iloc[i]['loan_status']\n",
    "        if raw_selected_features['verification_status'].iloc[i] == \"Source Verified\":\n",
    "            df_processed.iat[i, df_processed.columns.get_loc('verification_status')] = 1.0\n",
    "        else:\n",
    "            df_processed.iat[i, df_processed.columns.get_loc('verification_status')] = 0.0\n",
    "        if raw_selected_features['loan_status'].iloc[i] == \"Fully Paid\":\n",
    "            df_processed.iat[i, df_processed.columns.get_loc('loan_status')] = 1.0\n",
    "        else:\n",
    "            df_processed.iat[i, df_processed.columns.get_loc('loan_status')] = 0.0\n",
    "\n",
    "    print(df_processed.shape)\n",
    "    print(df_processed.head)\n",
    "    df_processed.to_csv(r'processed_data2.csv', index=False)\n",
    "\n",
    "\n",
    "preProcessData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>installment</th>\n",
       "      <th>dti</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>total_pymnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>10.65</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>162.87</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5861.071414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>15.27</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>59.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>15.96</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>84.33</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3003.653644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>13.49</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>339.31</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12226.302212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>156.46</td>\n",
       "      <td>11.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5631.377753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.0</td>\n",
       "      <td>18.64</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>109.43</td>\n",
       "      <td>5.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3938.144334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60.0</td>\n",
       "      <td>21.28</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>152.39</td>\n",
       "      <td>5.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>646.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60.0</td>\n",
       "      <td>12.69</td>\n",
       "      <td>5375.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>121.45</td>\n",
       "      <td>18.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1476.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60.0</td>\n",
       "      <td>14.65</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>153.45</td>\n",
       "      <td>16.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7677.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.0</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>402.54</td>\n",
       "      <td>10.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13943.080000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   term  int_rate  loan_amnt  annual_inc  installment    dti  \\\n",
       "0  36.0     10.65     5000.0     24000.0       162.87  27.65   \n",
       "1  60.0     15.27     2500.0     30000.0        59.83   1.00   \n",
       "2  36.0     15.96     2400.0     12252.0        84.33   8.72   \n",
       "3  36.0     13.49    10000.0     49200.0       339.31  20.00   \n",
       "4  36.0      7.90     5000.0     36000.0       156.46  11.20   \n",
       "5  36.0     18.64     3000.0     48000.0       109.43   5.35   \n",
       "6  60.0     21.28     5600.0     40000.0       152.39   5.55   \n",
       "7  60.0     12.69     5375.0     15000.0       121.45  18.08   \n",
       "8  60.0     14.65     6500.0     72000.0       153.45  16.12   \n",
       "9  36.0     12.69    12000.0     75000.0       402.54  10.78   \n",
       "\n",
       "   verification_status  loan_status   total_pymnt  \n",
       "0                  0.0          1.0   5861.071414  \n",
       "1                  1.0          0.0   1008.710000  \n",
       "2                  0.0          1.0   3003.653644  \n",
       "3                  1.0          1.0  12226.302212  \n",
       "4                  1.0          1.0   5631.377753  \n",
       "5                  1.0          1.0   3938.144334  \n",
       "6                  1.0          0.0    646.020000  \n",
       "7                  0.0          0.0   1476.190000  \n",
       "8                  0.0          1.0   7677.520000  \n",
       "9                  1.0          1.0  13943.080000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed_data2.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['R'] = df.apply(lambda row: min(1,row.total_pymnt/row.loan_amnt), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>installment</th>\n",
       "      <th>dti</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>10.65</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>162.87</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5861.071414</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>15.27</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>59.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.710000</td>\n",
       "      <td>0.403484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>15.96</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>84.33</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3003.653644</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>13.49</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>339.31</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12226.302212</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>156.46</td>\n",
       "      <td>11.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5631.377753</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.0</td>\n",
       "      <td>18.64</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>109.43</td>\n",
       "      <td>5.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3938.144334</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60.0</td>\n",
       "      <td>21.28</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>152.39</td>\n",
       "      <td>5.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>646.020000</td>\n",
       "      <td>0.115361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60.0</td>\n",
       "      <td>12.69</td>\n",
       "      <td>5375.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>121.45</td>\n",
       "      <td>18.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1476.190000</td>\n",
       "      <td>0.274640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60.0</td>\n",
       "      <td>14.65</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>153.45</td>\n",
       "      <td>16.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7677.520000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.0</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>402.54</td>\n",
       "      <td>10.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13943.080000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   term  int_rate  loan_amnt  annual_inc  installment    dti  \\\n",
       "0  36.0     10.65     5000.0     24000.0       162.87  27.65   \n",
       "1  60.0     15.27     2500.0     30000.0        59.83   1.00   \n",
       "2  36.0     15.96     2400.0     12252.0        84.33   8.72   \n",
       "3  36.0     13.49    10000.0     49200.0       339.31  20.00   \n",
       "4  36.0      7.90     5000.0     36000.0       156.46  11.20   \n",
       "5  36.0     18.64     3000.0     48000.0       109.43   5.35   \n",
       "6  60.0     21.28     5600.0     40000.0       152.39   5.55   \n",
       "7  60.0     12.69     5375.0     15000.0       121.45  18.08   \n",
       "8  60.0     14.65     6500.0     72000.0       153.45  16.12   \n",
       "9  36.0     12.69    12000.0     75000.0       402.54  10.78   \n",
       "\n",
       "   verification_status  loan_status   total_pymnt         R  \n",
       "0                  0.0          1.0   5861.071414  1.000000  \n",
       "1                  1.0          0.0   1008.710000  0.403484  \n",
       "2                  0.0          1.0   3003.653644  1.000000  \n",
       "3                  1.0          1.0  12226.302212  1.000000  \n",
       "4                  1.0          1.0   5631.377753  1.000000  \n",
       "5                  1.0          1.0   3938.144334  1.000000  \n",
       "6                  1.0          0.0    646.020000  0.115361  \n",
       "7                  0.0          0.0   1476.190000  0.274640  \n",
       "8                  0.0          1.0   7677.520000  1.000000  \n",
       "9                  1.0          1.0  13943.080000  1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryamamidyala/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.19002382818703822\n",
      "MSE: 0.07344952004957706\n",
      "RMSE: 0.27101571919277495\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"loan_amnt\", \"annual_inc\", \"dti\", \"term\", \"verification_status\"]]\n",
    "y = df[[\"R\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Create a Gaussian Regressor\n",
    "clf=RandomForestRegressor(n_estimators=50)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "print(\"MAE:\" , metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
